 % For referencing the chapter elsewhere, use \ref{Chapter1} 

\chapter{Orderless Levelset method}\label{chapter:OL}
\lhead{\cref{chapter:OL} \emph{Orderless Levelset method}} % This is for the header on each page - perhaps a shortened title

\section{Formulation in terms of Locally Orderless Images}\label{section:OLform}
Chan \& Vese's energy based functional \eqref{F1} can be formulated in terms of Locally Orderless Images. Let $I:\Omega\to \Gamma$ be the image and let $\phi:\Omega\to\R$ be the levelset function, where $\Omega\subset \R^k$ is the image domain and $\Gamma\subset\R$ are the intensity values. Assume that $\Gamma$, the intensity values, is a positive bounded set and suppose that $c_1,c_2\in \Gamma$. Taking those functions into account, we formulate the joint histogram as in \cite{dar.11}:
\begin{equation}
  h_{I,\phi}(i,j,\vec{x}_0,\alpha,\vec{\beta},\vec{\sigma}) = (P_1(G(\vec{x},\sigma_1)*I(\vec{x})-i,\beta_1)P_2(G(\vec{x},\sigma_2)*\phi(\vec{x})-j,\beta_2))*W(\vec{x}_0,\alpha),
\end{equation}
$P_1$ and $P_2$ are Parzen windows, $G$ and $W$ are kernels as in \cref{chapter:LOI}.\\
Thus we use the Locally Orderless Images notion over the levelset function $\phi$ and the image $I$ and combine them to a joint histogram representation. Note that the spatial information of both image and levelset is discarded.\\
The ``Locally Orderless'' property has no immediate use in this formulation of the levelset method, even though it might be applicable in further work on this method. For now, we introduce the Orderless Levelset functional by letting $\alpha\to \infty$, then the spatial window $W(\vec{x}_0,\alpha)$ will tend to a constant value $K$ on the whole $\Omega$-domain. Thus the histogram simplifies to
\begin{equation}
  \begin{split}
    h_{I,\phi}(i,j,\vec{x}_0,\alpha,\vec{\beta},\vec{\sigma})\to h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) &= \int _\Omega KP_1(G(\vec{x},\sigma_1)*I(\vec{x})-i,\beta_1)P_2(G(\vec{x},\sigma_2)*\phi(\vec{x})-j,\beta_2)\df x_0\\
    &= P_1(G(\vec{x},\sigma_1)*I(\vec{x})-i,\beta_1)P_2(G(\vec{x},\sigma_2)*\phi(\vec{x})-j,\beta_2),
  \end{split}
\end{equation}

because the $W$ defined in \eqref{loikernel} integrates to 1.\\

In order to propose the Chan \& Vese functional in terms of orderless histograms, the following considerations are made:\\
* The length term can be represented by integrating the histogram over the intensity values $i$ and only considering the 0'th levelcurve by picking $j=0$.\\
* The area term can be represented by integrating over all intensity values $i$, but only over the positive levelset values.\\
* The similarity measure terms can be constructed by choosing the positive and negative levelset values and multiplying them with $\abs{i-c_1}^2$.\\

The considerations above yield the following functional that resembles Chan \& Vese's model:
\begin{equation}
  \begin{split}
    F(\phi,c_1,c_2) &= \mu \int 1_\Gamma(i) h_{I,\phi}(i,0,\vec{\beta},\vec{\sigma})\df m(i) + \nu\int 1_{\Gamma}(i)1_{R_+}(j) h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m_2(i,j)\\
    &+ \lambda_1\int 1_\Gamma(i) 1_{\R_+}(j) \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m_2(i, j)\\
    &+ \lambda_2\int 1_\Gamma(i) 1_{\R_-}(j) \abs{i-c_2}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m_2(i, j),
  \end{split}\label{LOLF}
\end{equation}
where $m_2$ is the two-dimensional Lebesgue measure and $m$ is the one-dimensional Lebesgue measure. Furthermore, $1_\Gamma(i), 1_{\R_+}(j)$ and $1_{\R_-}(i)$ are indicator functions to measure the segments and regularizations according to the Chan Vese functional \eqref{F1}.\\

To prove existence, the following theorem is used:
\begin{theorem}[Tonelli]\label{Tonelli}
Let $(\mathcal{X},\;\mathbb{E},\mu),(\mathcal{Y},\mathbb{F},\nu)$ be two $\sigma$-finite measure spaces, and let $f\in\mathcal{M}^+(\mathcal{X}\times \mathcal{Y},\mathbb{E}\otimes\mathbb{F})$. It holds that
\begin{equation}
\int f \df\mu\otimes\nu = \int\int f(x,y) \df \nu(y) \df \mu(x)
\end{equation}
\end{theorem}
\textbf{Proof.} This theorem is proven in \cite[p.~195]{hansen.09}.\hfill\qed\\

Fix $\vec{\sigma}, \vec{\beta}, c_1, c_2$ and let $(\Gamma\times \R_+,\mathbb{B}^2(\R),m_2(i,j))$ be the $\sigma$-finite measure space on which $f(i,j) = \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\sigma},\vec{\beta})$ is defined. The Parzen window is per definition integrable, in particular measurable and $\abs{i-c_1}^2$ is measurable, since it is continuous. This implies that $f$ is measurable, because $f$ is the product of measurable functions. Since $f$ is positive, we can use Tonelli's theorem \eqref{Tonelli}, thus
\begin{equation}
  \begin{split}
    &\int 1_\Gamma(i) 1_{\R_+}(j) \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m_2(i, j)\\
    = &\int\int 1_\Gamma(i) 1_{\R_+}(j) \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m(i) \df m(j).
  \end{split}
\end{equation}
Furthermore, we can bound $\abs{i-c_1}^2$ by a constant $K$, because $\Gamma$ is assumed to be a bounded interval and $c_1\in\Gamma$. This gives
\begin{equation}
  \begin{split}
    &\int\int 1_\Gamma(i) 1_{\R_+}(j) \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m(i) \df m(j)\\
    \leq &\int\int 1_\Gamma(i) 1_{\R_+}(j) K h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df m(i) \df m(j) \leq K < \infty,
  \end{split}
\end{equation}
because the Parzen windows integrate to 1 on the whole domain.\\
Similar arguments hold for the other terms in \eqref{LOLF}, hence $F$ is well defined and finite.\\

\begin{lemma}\label{DiffLemma}
 Let $\emptyset \neq (a,b)\subset\R$ be a non-degenerate open interval and $u:(a,b)\times \mathcal{X}\to \R$ be a function satisfying
\begin{enumerate}
  \item $x\mapsto u(t,x)$ is integrable for every fixed $t\in(a,b)$.
  \item $t\mapsto u(t,x)$ is differentiable for every fixed $x\in X$
  \item $\abs{\frac{\partial}{\partial t} u(t,x)}\leq w(x)$ for all $(t,x)\in (a,b)\times X$, where $w$ is an integrable function over $X$.
\end{enumerate}

Then the function 
\begin{equation}
  t\mapsto v(t):=\int u(t,x) \df x
\end{equation}

is differentiable and its derivative is
\begin{equation}
  \frac{\partial}{\partial t} v(t) = \int \frac{\partial}{\partial t} u(t,x) \df x
\end{equation}
\end{lemma}
\textbf{Proof} This lemma is proven in \cite[p.~92]{schilling.11}, lemma 11.5.\hfill\qed\\

To find the values $c_1,c_2$ that minimize $F(\phi,c_1,c_2)$, assume that $\phi$ is fixed. The minimum is found by finding $c_1$ such that $\partial F/\partial c_1 =0$ and checking $\partial^2 F/\partial c_1^2 > 0$. \\
Thus, lemma \ref{DiffLemma} is applied:\\
1) For fixed $c_1$, we require $(i,j)\mapsto \abs{i-c_1}^2h_{I,\phi}(i,j,\sigma,\beta)$ to be integrable for every $c_1\in\R$. But this is given since the terms in the functional are integrable.\\
2) We have to assume that  $c_1 \mapsto \abs{i-c_1}h_{I,\phi}(i,j,\sigma,\beta)$ is differentiable for every fixed $i,j\in \R$. But $\abs{i-c_1}^2$ is differentiable on $\R_+$ and the rest does not depend on $c_1$, so this is true.\\
3) The derivative needs to be less or equal an integrable function over the whole domain. But this is clear, since $\abs{\partial_{c_1}\abs{i-c_1}^2}$ is also bounded by a constant.\\
Hence we can write
\begin{equation}
  \begin{split}
    \frac{\partial F}{\partial c_1} &= \frac{\partial }{\partial c_1} \int_{\R_+}\int_{\Gamma}\abs{i-c_1}^2 h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j 
    = \int_{\R_+}\int_{\Gamma}\frac{\partial }{\partial c_1}\abs{i-c_1}^2 h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j \\
    &= \int_{\R_+} \int_\R-2\abs{i-c_1}\frac{(i-c_1)}{\abs{i-c_1}} h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j 
    = \int_{\R_+} \int_\R-2(i-c_1) h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j = 0.
  \end{split}
\end{equation}

By rearranging and splitting the integral, assuming $\int_{\R_+}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j\neq 0$, we obtain
\begin{equation}
  c_1 = \frac{\int_{\R_+}  \int_{\Gamma}i\cdot h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j}{\int_{\R_+}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j},
\end{equation}

and 
\begin{equation}
  \frac{\partial^2 F}{\partial c_1^2} = \frac{\partial}{\partial c_1}\int_{\R_+}\int_{\Gamma}-2(i-c_1) h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j = \int_{\R_+}\int_{\Gamma}2 h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j>0.
\end{equation}

Similar arguments also hold for $c_2$, thus assuming $\int_{\R_-}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j\neq 0$ yields
\begin{equation}
  c_2 = \frac{\int_{\R_-}\int_{\Gamma} i\cdot h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j}{\int_{\R_-}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j}.
\end{equation}

If $\int_{\R_-}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j=0$ or $\int_{\R_+}\int_{\Gamma}h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) \df i\df j = 0$, the choice of $c_1$, $c_2$ does not matter, since the terms will vanish.

\section{Derivatives of Orderless Levelset method}\label{section:OLder}
We are interested in minimizing the functional $F$, hence we find the gradient with respect to $\phi$. Let $\partial_\phi$ denote the differential operator wrt. $\phi$. Thus the differential is given by
\begin{equation}
  \partial_\phi F = \partial_\phi \mathcal{L} + \partial_\phi \mathcal{A} + \partial_\phi\mathcal{M}_{inside} + \partial_\phi \mathcal{M}_{outside},
\end{equation}

where $\mathcal{A}$ denotes the area term and $\mathcal{L}$ denotes the length term from \eqref{LOLF}\\

Again lemma \ref{DiffLemma} is used. The same arguments as before hold, but for condition 2) we also have to assume that $P_2$ is differentiable and for condition 3) that the absolute derivative can be majorized by an integrable function.\\
Considering the terms seperately, the derivative of the inside similarity measure $\mathcal{M}_{inside}$ is found to be
\begin{equation}
  \partial_\phi \mathcal{M}_{inside} = \partial_\phi \left( \lambda_1\int_{\R_+} \int_{\Gamma} \abs{i-c_1}^2h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df i\df j\right) = \lambda_1\int_{\R_+} \int_{\Gamma} \abs{i-c_1}^2 \partial_\phi h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df i\df j,
\end{equation}

where
\begin{equation}
  \begin{split}
    \partial_\phi h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma}) &= \partial_\phi \left(P_1(G(\vec{x},\sigma_1)*I(\vec{x})-i,\beta_1)P_2(G(\vec{x},\sigma_2)*\phi(\vec{x})-j,\beta_2)\right)\\ 
    &= P_1(G(\vec{x},\sigma_1)*I(\vec{x})-i,\beta_1)\partial_\phi P_2(G(\vec{x},\sigma_2)*\phi(\vec{x})-j,\beta_2).
  \end{split}
\end{equation}

The term outside similarity measure $\mathcal{M}_{outside}$ is differentiated similarly, hence
\begin{equation}
\partial_\phi \mathcal{M} = \lambda_2\int_{\R_-} \int_{\Gamma} \abs{i-c_1}^2 \partial_\phi h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df i\df j,
\end{equation}

and likewise the length and area terms $\mathcal{L}$ and $\mathcal{A}$
\begin{align}
  \partial_\phi \mathcal{L} &= \mu \int_{\R_+} \int_{\Gamma} \partial_\phi h_{I,\phi}(i,j,\vec{\beta},\vec{\sigma})\df i\df j,\\
  \partial_\phi \mathcal{A} &= \mu  \int_{\Gamma} \partial_\phi h_{I,\phi}(i,0,\vec{\beta},\vec{\sigma})\df i\df j.
\end{align}

\section{B-splines}
This section contains lemmas and theorems about B-splines necessary in the next section. Since I was not able to find sufficient material on B-splines, the definition and properties are stated here and necessary conditions on the differentiability and integrability of B-splines are proven. The theory is based on \cite[chap.~6.5]{kin.02}.\\

\begin{definition}[B-splines]\label{Bspline}
Let $...,t_{-1},t_0<t_1<...$ be a real valued, possibly infinite, knot sequence. The basis B-splines $B_i^0: \R \to [0,1]$ of degree 0 are defined as
\begin{equation}
  B_i^0(x) = 
  \begin{cases}
    1 & \mbox{ if } t_i\leq x < t_{i+1}\\
    0 & \mbox{ otherwise}
  \end{cases}
\end{equation}
for $n\in\N$.

The basis B-splines $B_i^k:\R\to [0,1]$ of degree $k$ are defined recursively by
\begin{equation}
  B_i^k(x) = \frac{x-t_i}{t_{i+k}-t_i} B_i^{k-1}(x) + \frac{t_{i+k}-x}{t_{i+k+1}-t_{i+1}} B_{i+1}^{k-1}(x) \quad \text{ for } k\geq 1,\;i\in \Z.\label{recurDef}
\end{equation}
\end{definition}
\vspace{0.5cm}
\begin{remark}[about B-splines]\label{remark}.
  \begin{enumerate}
    \item The support of $B_i^k$ is the interval $[t_i,t_{i+k+1})$.
    \item $\displaystyle\sum_{i=-\infty}^\infty B_i^k(x) = 1$ for all $x$.\label{property2}
  \end{enumerate}
\end{remark}
\vspace{0.5cm}
\begin{lemma}[Derivatives of B-splines]\label{derBspline} 
The derivatives of B-spline basis functions are calculated as follows
  \begin{equation}
    \frac{\df}{\df x} B_i^k(x) = \frac{k}{t_{i+k}-t_i}B_i^{k-1}(x) - \frac{k}{t_{i+k+1}-t_{i+1}}B_{i+1}^{k-1}(x)\label{DerBspline}
  \end{equation}
  for $k\geq 2$. The equation holds for $k=1$ in all $x$ except $t_i,\,t_{i+1},\,t_{i+2}$.
  Furthermore, for $k\geq 1$, the basis B-splines $B_i^k$ belong to $C^{k-1}(\R)$.
\end{lemma}\
\textbf{Proof}. For convenience, let 
\[
  \alpha_i^k = \frac{x-t_i}{t_{i+k}-t_{i}} \quad\mbox{and}\quad \beta_i^k = \frac{\df}{\df x} \alpha_i^k = \frac{1}{t_{i+k}-t_{i}},
\]
thus
\[
  1-\alpha_{i+1}^k = \frac{t_{i+1}-x}{t_{i+k+1}-t_{i+1}} \quad\mbox{and}\quad -\beta_{i+1}^k = \frac{\df}{\df x} (1-\alpha_{i+1}^k) = -\frac{1}{t_{i+k+1}-t_{i+1}}.
\]

Let $k=1$ and assume $x\neq t_i,\,t_{i+1},\,t_{i+2}$. We find that
\begin{align}
  \frac{\df}{\df x} B_i^1(x) &= \frac{\df}{\df x} \left(1_{[t_i,t_{i+1})}(x) \alpha_i^1 + 1_{[t_{i+1},t_{i+2})}(x) (1-\alpha_{i+1}^1)\right)\\
  &= 1_{[t_i,t_{i+1})}(x) \frac{1}{t_{i+1}-t_{i}} - 1_{[t_{i+1},t_{i+2})}(x) \frac{1}{t_{i+2}-t_{i+1}},\\
  &= \frac{1}{t_{i+1}-t_{i}}B_i^0(x) - \frac{1}{t_{i+2}-t_{i+1}} B_{i+1}^0(x),
\end{align}

which exactly is the formula \eqref{DerBspline} for $k=1$.\\

Now let $k=2$, by using the recursive definition of B-splines \eqref{recurDef} twice, we get
\begin{align}
  B_i^2 &= \alpha_i^2(\alpha_i^1 B_i^0 + (1-\alpha_{i+1}^1)B_{i+1}^0) + (1-\alpha_{i+1}^2)(\alpha_{i+1}^1B_{i+1}^0 + (1-\alpha_{i+2})B_{i+2}^0)\\
  &= \alpha_i^2\alpha_i^1B_i^0 + [\alpha_i^2(1-\alpha_{i+1}^1) + (1-\alpha_{i+1}^2)\alpha_{i+1}^1]B_{i+1}^0 + (1-\alpha_{i+1}^2)(1-\alpha_{i+2}^1)B_{i+2}^0
\end{align}
Finding the derivative of the terms independently gives
\begin{align}
  &\frac{\df}{\df x} (\alpha_i^2\alpha_i^1B_i^0) = (\beta_i^2\alpha_i^1 + \alpha_i^2\beta_i^1)B_i^0\\
  &= \left(\frac{x-t_i}{(t_{i+2}-t_i)(t_{i+1}-t_i)} + \frac{x-t_i}{(t_{i+2}-t_i)(t_{i+1}-t_i)}\right)B_i^0 = \left(\frac{2(x-t_i)}{(t_{i+2}-t_i)(t_{i+1}-t_i)}\right)B_i^0\\
  & = \frac{2}{t_{i+2}-t_i}B_i^1
\end{align}
for $x\in [t_i,t_{i+1})$, 
\begin{align}
  &\frac{\df}{\df x} ([\alpha_i^2(1-\alpha_{i+1}^1) + (1-\alpha_{i+1}^2)\alpha_{i+1}^1]B_{i+1}^0)\\
  &= [\beta_i^2(1-\alpha_{i+1}^1) - \alpha_i^2\beta_{i+1}^1 - \beta_{i+1}^2\alpha_{i+1}^1 + (1-\alpha_{i+1}^2)\beta_{i+1}^1]B_{i+1}^0\\
  &= \left(\frac{t_{i+2}-x}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})}-\frac{x-t_i}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})} - \frac{x-t_{i+1}}{(t_{i+3}-t_{i+1})(t_{i+2}-t_{i+1})}\right.\\
  &\left.+ \frac{t_{i+3}-x}{(t_{i+3}-t_{i+1})(t_{i+2}-t_{i+1})}\right)B_{i+1}^0\\ 
  &= \frac{t_{i+2}-2x}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})}-\frac{2x-t_{i+1}}{(t_{i+3}-t_{i+1})(t_{i+2}-t_{i+1})} + \frac{t_{i+2}t_{i+3}-t_it_{i+1}}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})(t_{i+3}-t_{i+1})}\\
  &= \frac{t_{i+2}-2x}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})}-\frac{2x-t_{i+1}}{(t_{i+3}-t_{i+1})(t_{i+2}-t_{i+1})} + \frac{t_{i+2}(t_{i+3}-t_{i+1}) + t_{i+1}(t_{i+2}-t_i)}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})(t_{i+3}-t_{i+1})}\\
  &= \frac{2(t_{i+2}-x)}{(t_{i+2}-t_i)(t_{i+2}-t_{i+1})}-\frac{2(x-t_{i+1})}{(t_{i+3}-t_{i+1})(t_{i+2}-t_{i+1})} = \frac{2}{t_{i+2}-t_i} B_i^1 - \frac{2}{t_{i+3}-t_{i+1}} B_{i+1}^1 
\end{align}
for $x\in [t_{i+1},t_{i+2})$ and
\begin{align}
  &\frac{\df}{\df x} ((1-\alpha_{i+1}^2)(1-\alpha_{i+2}^1))B_{i+2}^0 = (-\beta_{i+1}^2(1-\alpha_{i+2}^1) -(1-\alpha_{i+1}^2)\beta_{i+2}^1)B_{i+2}^0\\
  &= - \frac{2(t_{i+3}-x)}{(t_{i+3}-t_{i+1})(t_{i+3}-t_{i+2})} = -\frac{2}{t_{i+3}-t_{i+1}}B_{i+1}^1
\end{align}
for $x\in [t_{i+2},t_{i+3})$. Since $B_i^1$ is clearly continuous, $B_i^2$ is $C^{1}(\R)$.\\

Now assume that \eqref{DerBspline} holds for $k$ and that $B_i^k$ is $C^{k-1}(\R)$. Then 
\begin{align}
  \frac{\df}{\df x} B_i^{k+1} &= \frac{\df}{\df x} \left(\alpha_i^{k+1} B_i^k + \alpha_{i+1}^{k+1}B_{i+1}^k\right)\\
  &= \beta_i^{k+1} B_i^k + \alpha_i^{k+1} \frac{\df}{\df x}B_i^k + \beta_{i+1}^{k+1} B_{i+1}^k + (1-\alpha_{i+1}^{k+1}) \frac{\df}{\df x}B_{i+1}^1\\
  \intertext{From the induction hypothesis, we have}
  \frac{\df}{\df x} B_i^{k+1} &= \alpha_i^{k+1}(k\beta_i^{k}B_i^{k-1} - k\beta_{i+1}^{k}B_{i+1}^{k-1}) + (1-\alpha_{i+1}^{k+1})(k\beta_{i+1}^{k}B_{i+1}^{k-1} - k\beta_{i+1}^k B_{i+1}^{k-1})\\
  &+ \beta_i^{k+1}B_i^k - \beta_{i+1}^{k+1}B_{i+1}^k.\\
  \intertext{By rearranging, we obtain}
  \frac{\df}{\df x} B_i^{k+1} &= \beta_i^{k+1} B_i^k - \beta_{i+1}^{k+1}B_{i+1}^k + k\alpha_i^{k+1}\beta_i^kB_i^{k-1} - k\alpha_i^{k+1}\beta_{i+1}^kB_{i+1}^{k-1}\\
  &+ k(1-\alpha_{i+1}^{k+1})\beta_{i+1}^kB_{i+1}^{k-1} - k(1-\alpha_{i+1}^{k+1})\beta_{i+1}^kB_{i+{k+1}}^{k-1}\\
  \intertext{Now notice that $\alpha_i^{k+1}\beta_i^{k} = \alpha_i^{k}\beta_i^{k+1}$ and $(1-\alpha_i^{k+1})\beta_{i+1}^{k} = (1-\alpha_{i+1}^{k})\beta_{i}^{k+1}$, thus}
  \frac{\df}{\df x} B_i^{k+1} &= \beta_i^{k+1} B_i^k - \beta_{i+1}^{k+1}B_{i+1}^k + k(\alpha_i^k\beta_i^{k+1}B_i^{k-1} + (1-\alpha_{i+1}^k)\beta_{i}^{k+1}B_{i+1}^{k-1})\\
  &- k(\alpha_{i+1}^k\beta_{i+1}^{k+1}B_{i+1}^{k-1} + (1-\alpha_{i+1}^k)\beta_{i+2}^{k+1}B_{i+2}^{k-1})\\
  \intertext{and the recursive definition yields}
  \frac{\df}{\df x} B_i^{k+1} &= \beta_i^{k+1} B_i^k - \beta_{i+1}^{k+1}B_{i+1}^k + \beta_{i}^{k+1}B_i^k - \beta_{i+1}^{k+1} B_{i+1}^k\\
  &= (k+1)\beta_{i}^{k+1}B_i^k - (k+1)\beta_{i+1}^{k+1} B_{i+1}^k.
\end{align}
By induction the formula \eqref{DerBspline} is proven. Furthermore, since $B_i^k$ was assumed to be $C^{k-1}(\R)$, we can conclude that $B_i^{k+1}$ is $C^k(\R)$.\hfill\qed\\

\begin{lemma}[Integral of B-splines]\label{intBspline}
The integral of B-splines are given by
\begin{equation}
\int_{-\infty}^x = \frac{t_{i+k+1}-t_i}{k+1} \sum_{j=i}^\infty B_j^{k+1}(x)
\end{equation}
\end{lemma}
\textbf{Proof.} From lemma \ref{derBspline} we obtain the following formula
\begin{equation}
  \frac{\df}{\df x} \sum_{i=-\infty}^\infty c_i B_i^k(x) = k\sum_{i=-\infty}^\infty \frac{c_i-c_{i-1}}{t_{i+k}-t_i}B_i^{k-1}, \quad k\geq 2.\label{IntBspline}
\end{equation}
Let 
\[
  c_j = \begin{cases}0 & \mbox{ if } j<i\\ 1 & \mbox{ if } j\geq i.\end{cases}
\]
Taking the derivative on both sides of \eqref{IntBspline} and using the formula stated above yields the following identity
\begin{equation}
B_i^k(x) = \frac{t_{i+k+1}-t_{i}}{k+1}(k+1)\frac{1}{t_{i+k+1}-t_{i}}B_i^k(x).
\end{equation}
Thus \eqref{IntBspline} holds, by noting that both sides reduce to 0 when $x = t_i$. \hfill\qed\\

\begin{proposition}\label{PWBspline}
A uniform B-spline with $t_{j+1}-t_j = 1$ for all knots is a Parzen window.
\end{proposition}
\textbf{Proof}. From lemma \ref{intBspline}, we know that the derivative of a basis B-spline function is given by \eqref{IntBspline}. Since the distance between the knots is 1, we have that $t_{i+k+1}-t_i = k+1$, thus the integral is just the sum over B-spline functions. The sum over all B-splines equals 1 as stated in remark \ref{remark}.\hfill\qed


\section{Optimization}\label{section:OLopt}
For the optimization process, a constant B-spline is used as the Parzen window over the image $I$ as defined in section \ref{HistIm}. Note that a constant B-spline integrates to 1, thus it is a Parzen window. Every pixel is chosen to represent one bin. The bin-size $\Delta i_m$ is thus the difference of successive intensities, the bin widths are not necessarily equidistant. Hence the isophotes are not extracted smoothly. This is not required, because the image is constant in our equation, it does not change finding the minimum of \eqref{LOLF}.\\
The kernel $G$ over the image $I$ is chosen to be a Gaussian kernel as stated in \eqref{loikernel}. 

For the levelset function $\phi$, the histogram is smoothed in order to be able to develop the levelset. A uniform cubic B-spline is chosen to represent the Parzen window over $\phi$, where the bin size is chosen to be 1. This particular choice is proven to be a Parzen window in proposition \ref{PWBspline}. We have assumed that $P_2$, the Parzen window over $\phi$ is differentiable, but B-splines of order greater or equal 2 are differentiable, as proven in lemma \ref{derBspline}. \\
The knots $t_i$ for the Parzen window are given by integers such that
\[
t_{-1},t_0,\dots,t_n = \lfloor\min_{(x,y)\in\Omega}\{\phi(x,y)\}\rfloor, \lfloor\min_{(x,y)\in\Omega}\{\phi(x,y)\}\rfloor, \dots, \lfloor\max_{(x,y)\in\Omega}\{\phi(x,y)\}\rfloor.
\]
The uniform B-spline is then given by

\begin{equation}
  P_2(t,\beta) = 
  \begin{bmatrix} t^3 & t^2 & t & 1 \end{bmatrix} 
  \frac{1}{6} 
  \begin{bmatrix}
    -1 &  3 & -3 & 1 \\
    3 & -6 &  3 & 0 \\
    -3 &  0 &  3 & 0 \\
    1 &  4 &  1 & 0 
  \end{bmatrix}
  \left[\begin{array}{l} 
      P_{i-1} \\
      P_{i} \\
      P_{i+1} \\
      P_{i+2}
    \end{array}\right],
\end{equation}

where $t = \phi-\lfloor \phi\rfloor \in [0,1]$ and $P_i$ are the control points such that $P_i$ handles whether the point lies in the inner segment, the outer segment or on the 0'th levelcurve. Thus

\begin{equation}
  P_i = 
  \begin{cases}
    \lambda_1(i-c_1)^2 + \nu & \mbox{ if } t_i \geq 0\\
    \lambda_2(i-c_2)^2 & \mbox{ if } t_i < 0\\
    \mu & \mbox{ if } t_i = 0
  \end{cases}
\end{equation}

In order to find the derivative of the functional \eqref{LOLF}, we need to find the derivative of the Parzen window, as explained in \sref{section:OLder}. The derivative is found to be

\begin{equation}
\partial_\phi  P_2(t,\beta) = 
  \begin{bmatrix} t^2 & t & 1 & 0 \end{bmatrix} 
  \frac{1}{6} 
  \begin{bmatrix}
    -1 &  3 & -3 & 1 \\
    3 & -6 &  3 & 0 \\
    -3 &  0 &  3 & 0 \\
    1 &  4 &  1 & 0 
  \end{bmatrix}
  \left[\begin{array}{l} 
      P_{i-1} \\
      P_{i} \\
      P_{i+1} \\
      P_{i+2}
    \end{array}\right].
\end{equation}

Since the spatial information, i.e. the position of the points in the image and the levelset, is discarded using the Locally Orderless representation, the Hessian matrix will be diagonal. Any two different pixels of $\phi$ are independent of each other, thus the partial second derivatives in the Hessian are 0 except on the diagonal. Because the derivatives behave so well, the levelset is evolved by taking steps in the steepest descent direction.